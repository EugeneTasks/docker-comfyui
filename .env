COMFYUI_ARGS="--lowvram --preview-method none --fp16-vae"
#2060 ti 32 ozy
#--lowvram --preview-method none --fp16-vae

#4090 
#sharing server
#--normalvram --preview-method none  --bf16-vae

#4090
#all server
#--highvram --preview-method none --bf16-vae

#if enought RAM use --fp32-vae 

COMFYUI_PORT_HOST=8188

CPU_MAX_LIMIT=4
RAM_MAX_LIMIT=16G

CPU_MIN_LIMIT=1
RAM_MIN_LIMIT=10G
#WARNING 
#RAM_MIN_LIMIT < MEMORY_SWAP_MAX_LIMIT, SWAP = MEMORY_SWAP_MAX_LIMIT - RAM_MIN_LIMIT
MEMORY_SWAP_MAX_LIMIT=20G

GPU_MEMORY_UTILIZATION=0.5

# https://docs.comfy.org/interface/settings/server-config

# ComfyUI Startup Arguments
# Add any of these flags to your COMFYUI_ARGS environment variable
# or the command line when running main.py.
# Example: COMFYUI_ARGS="--lowvram --preview-method none"

# -- Network --

# --listen [ip_address]
# Sets the IP address the server binds to. Default is 127.0.0.1 (local access only).
# Use 0.0.0.0 for LAN access.

# --port [port_number]
# The port number the server listens on. Default is typically 8188.

# --tls-key-file [path]
# Path to the TLS private key file required for HTTPS.

# --tls-cert-file [path]
# Path to the TLS certificate file required for HTTPS.

# --enable-cors-header [domain | "*"]
# Enables Cross-Origin Resource Sharing, allowing browsers to access the server from different domains.

# --max-upload-size [size_in_mb]
# Limits the maximum size of single file uploads in megabytes. Default is 100MB.

# -- CUDA --

# --cuda-device [index]
# Specifies which NVIDIA graphics card to use (e.g., 0 for the first card, 1 for the second).

# --cuda-malloc
# Controls whether to use CUDAâ€™s memory allocator, which can improve memory management efficiency.

# -- Inference --

# --unet-precision [auto|fp64|fp32|fp16|bf16|fp8_e4m3fn|fp8_e5m2]
# Controls the computational precision of the UNET core component. Lower precision saves VRAM but may affect quality.

# --vae-precision [auto|fp16|fp32|bf16]
# Controls the computational precision of the VAE, affecting image encoding/decoding quality and speed.

# --vae-on-cpu
# Forces the VAE to run on the CPU, which saves a significant amount of VRAM but will reduce processing speed.

# --text-encoder-precision [auto|fp8_e4m3fn|fp8_e5m2|fp16|fp32]
# Controls the computational precision of the text prompt encoder.

# -- Memory --

# --force-channels-last
# Changes the data arrangement in memory, which may improve performance on certain hardware.

# --directml [device_index]
# Specifies the device index when using DirectML acceleration on Windows (mainly for AMD/Intel GPUs).

# --disable-ipex-optimizations
# Disables Intel CPU optimizations.

# --lowvram
# Low VRAM mode. Uses the minimal amount of VRAM, which may affect generation quality.

# --normalvram
# Standard VRAM mode. Balances VRAM usage and performance.

# --highvram
# High VRAM mode. Uses more VRAM for potentially better performance.

# --novram
# No VRAM usage mode. Runs entirely on system memory.

# --cpu
# CPU-only mode. Does not use the graphics card for processing.

# --disable-smart-memory
# Disables automatic memory optimization, forcing models to be offloaded to system memory to free VRAM.

# -- Preview --

# --preview-method [none|auto|latent2rgb|taesd]
# Controls how intermediate results are previewed during generation. 'none' disables previews.

# -- Attention --

# --cross-attention-method [auto|split|quad|pytorch]
# Controls the algorithm used for attention computation, trading off between quality, speed, and VRAM.

# --force-attention-upcast
# Forces high-precision attention computation to improve quality, but increases VRAM usage.

# --prevent-attention-upcast
# Disables high-precision attention computation to save VRAM.

# -- General --

# --disable-xformers
# Disables optimizations from the xFormers library. Use this for troubleshooting or when needing more precise computations.

# --deterministic
# Forces PyTorch to use slower, deterministic algorithms when possible to improve result reproducibility.

# --enable-untested-optimizations
# Enables experimental optimizations that may improve speed but could potentially degrade generation quality.

# --dont-print-server
# Prevents displaying server runtime information and logs in the console.

# --disable-metadata-saving
# Prevents saving workflow information (prompt metadata) in the generated image files.

# --disable-custom-nodes
# Prevents loading all third-party custom nodes, useful for troubleshooting.

# -- Directories --

# --input-directory [path]
# Sets the default storage path for input files.

# --output-directory [path]
# Sets the default save path for generation results.